# API Utilitaires

## Vue d'ensemble

Les modules utilitaires fournissent des fonctionnalit√©s de support pour le preprocessing, l'optimisation m√©moire, et le monitoring du syst√®me.

## Module `src.utils.preprocessing`

Utilitaires pour l'extraction et le traitement des frames vid√©o.

### Fonctions Principales

#### `extract_frames_from_video()`

Extrait des frames d'une vid√©o √† intervalles r√©guliers.

```python
def extract_frames_from_video(
    video_path: str,
    seconds_per_frame: float = 2.0,
    max_frames: int = 10
) -> List[Image.Image]:
```

**Param√®tres** :
- `video_path` : Chemin vers le fichier vid√©o
- `seconds_per_frame` : Intervalle d'extraction en secondes
- `max_frames` : Limite du nombre de frames extraites

**Retourne** : Liste d'images PIL

**Exemple** :
```python
from src.utils.preprocessing import extract_frames_from_video

frames = extract_frames_from_video(
    "surveillance.mp4",
    seconds_per_frame=1.5,
    max_frames=8
)
print(f"Extracted {len(frames)} frames")
```

#### `extract_keyframes()`

S√©lection intelligente des frames les plus repr√©sentatives.

```python
def extract_keyframes(
    video_path: str,
    target_frames: int = 5
) -> List[Image.Image]:
```

**Algorithme** :
- Analyse de variance entre frames cons√©cutives
- D√©tection des changements significatifs de contenu
- R√©partition √©quilibr√©e dans la dur√©e de la vid√©o

**Exemple** :
```python
keyframes = extract_keyframes("long_video.mp4", target_frames=3)
# S√©lectionne les 3 frames les plus repr√©sentatives
```

#### `preprocess_frame()`

Optimise une frame pour l'analyse par les mod√®les VLM.

```python
def preprocess_frame(
    frame: Image.Image,
    target_size: Tuple[int, int] = (384, 384)
) -> Image.Image:
```

**Traitements appliqu√©s** :
- Redimensionnement √† la taille cible
- Conversion en RGB si n√©cessaire
- Normalisation de l'√©clairage
- Ajustement du contraste

#### `batch_preprocess_frames()`

Traitement par lots pour optimiser les performances.

```python
def batch_preprocess_frames(
    frames: List[Image.Image],
    batch_size: int = 4
) -> List[Image.Image]:
```

**Avantages** :
- Traitement parall√®le des frames
- Optimisation m√©moire
- Monitoring automatique des ressources

## Module `src.utils.memory_optimizer`

Gestionnaire intelligent de la m√©moire GPU et CPU.

### Classe `MemoryOptimizer`

```python
from src.utils.memory_optimizer import memory_optimizer

# Instance globale disponible
optimizer = memory_optimizer
```

### M√©thodes Principales

#### `check_memory_pressure()`

V√©rifie si le syst√®me est sous pression m√©moire.

```python
def check_memory_pressure(self) -> bool:
```

**Retourne** : `True` si la m√©moire est satur√©e

**Exemple** :
```python
if memory_optimizer.check_memory_pressure():
    print("‚ö†Ô∏è M√©moire satur√©e, optimisation n√©cessaire")
    memory_optimizer.aggressive_cleanup()
```

#### `aggressive_cleanup()`

Lance un nettoyage agressif de la m√©moire.

```python
def aggressive_cleanup(self) -> Dict[str, float]:
```

**Actions** :
- Collecte du garbage collector Python
- Nettoyage cache PyTorch
- Lib√©ration m√©moire GPU
- D√©chargement mod√®les non utilis√©s

**Retourne** : Statistiques de nettoyage

#### `auto_configure_settings()`

Configuration automatique selon les ressources disponibles.

```python
def auto_configure_settings(self) -> None:
```

**Ajustements automatiques** :
- Taille des lots de traitement
- Activation du nettoyage automatique
- Fraction de m√©moire GPU utilisable
- Nombre maximum de frames

#### `get_memory_stats()`

Statistiques d√©taill√©es de l'utilisation m√©moire.

```python
def get_memory_stats(self) -> Dict[str, Any]:
```

**Informations retourn√©es** :
- M√©moire CPU utilis√©e/disponible
- M√©moire GPU utilis√©e/disponible (si CUDA)
- Nombre d'objets en m√©moire Python
- √âtat des caches PyTorch

### D√©corateur `@memory_monitor`

Monitoring automatique de l'utilisation m√©moire.

```python
from src.utils.memory_optimizer import memory_monitor

@memory_monitor("Analyse VLM")
def analyze_with_vlm(frames):
    # Code d'analyse
    return vlm.analyze(frames)

# Ou en context manager
with memory_monitor("Preprocessing"):
    frames = extract_frames_from_video(video_path)
```

**Fonctionnalit√©s** :
- Monitoring avant/apr√®s ex√©cution
- Logs automatiques des variations m√©moire
- Alerte en cas de fuite m√©moire
- Statistiques de performance

## Utilitaires de Configuration GPU

### `check_gpu_availability()`

V√©rifie la disponibilit√© et les capacit√©s GPU.

```python
def check_gpu_availability() -> Dict[str, Any]:
```

**Informations retourn√©es** :
```python
{
    "cuda_available": True,
    "device_count": 1,
    "current_device": 0,
    "device_name": "NVIDIA GeForce RTX 3080",
    "total_memory_gb": 10.0,
    "free_memory_gb": 8.2,
    "compute_capability": (8, 6)
}
```

### `get_optimal_device()`

S√©lectionne automatiquement le meilleur device disponible.

```python
def get_optimal_device() -> str:
```

**Logique de s√©lection** :
- GPU CUDA si disponible et suffisant VRAM
- GPU MPS (Apple Silicon) si disponible
- CPU en fallback

## Module Logging

### Configuration Intelligente

```python
from src.utils.logging import setup_logging

# Configuration automatique selon l'environnement
setup_logging(level="INFO", enable_memory_logs=True)
```

### Formatters Personnalis√©s

Le syst√®me utilise des formatters enrichis :

```python
# Exemple de log avec contexte
logger.info("üìΩÔ∏è Extraction: 8 frames en 2.34s")
logger.warning("‚ö†Ô∏è M√©moire GPU: 85% utilis√©e")
logger.error("‚ùå √âchec chargement mod√®le KIM: VRAM insuffisante")
```

## Exemples d'Usage Combin√©s

### Pipeline Complet Optimis√©

```python
from src.utils.preprocessing import extract_keyframes, batch_preprocess_frames
from src.utils.memory_optimizer import memory_monitor

@memory_monitor("Pipeline complet")
def optimized_video_processing(video_path: str):
    # 1. Extraction intelligente
    frames = extract_keyframes(video_path, target_frames=5)
    
    # 2. Preprocessing par lots
    processed_frames = batch_preprocess_frames(frames, batch_size=2)
    
    # 3. V√©rification m√©moire avant analyse
    if memory_optimizer.check_memory_pressure():
        memory_optimizer.aggressive_cleanup()
    
    return processed_frames
```

### Monitoring de Session

```python
def monitor_analysis_session():
    """Monitoring complet d'une session d'analyse"""
    
    initial_stats = memory_optimizer.get_memory_stats()
    print(f"M√©moire initiale: {initial_stats['cpu_used_gb']:.1f}GB CPU")
    
    if initial_stats['gpu_available']:
        print(f"GPU: {initial_stats['gpu_used_gb']:.1f}/{initial_stats['gpu_total_gb']:.1f}GB")
    
    # Session d'analyse
    for video in video_list:
        with memory_monitor(f"Analyse {video}"):
            result = orchestrator.analyze(video, section, time, density)
            
            # Nettoyage p√©riodique
            if memory_optimizer.check_memory_pressure():
                stats = memory_optimizer.aggressive_cleanup()
                print(f"üßπ Nettoyage: {stats['memory_freed_mb']:.1f}MB lib√©r√©s")
    
    final_stats = memory_optimizer.get_memory_stats()
    memory_diff = final_stats['cpu_used_gb'] - initial_stats['cpu_used_gb']
    print(f"Variation m√©moire session: {memory_diff:+.1f}GB")
```

### Configuration Adaptative

```python
def adaptive_configuration():
    """Configuration qui s'adapte aux ressources disponibles"""
    
    gpu_info = check_gpu_availability()
    
    if gpu_info['cuda_available']:
        vram_gb = gpu_info['free_memory_gb']
        
        if vram_gb >= 8:
            # Configuration haute performance
            settings.config.batch_size = 6
            settings.config.primary_vlm = ModelType.KIM
            settings.config.cleanup_after_analysis = False
            
        elif vram_gb >= 4:
            # Configuration √©quilibr√©e
            settings.config.batch_size = 3
            settings.config.primary_vlm = ModelType.SMOLVLM
            settings.config.cleanup_after_analysis = True
            
        else:
            # Configuration √©conomique
            settings.config.batch_size = 1
            settings.config.primary_vlm = ModelType.SMOLVLM
            settings.config.cleanup_after_analysis = True
            
    else:
        # Configuration CPU uniquement
        settings.config.batch_size = 1
        settings.config.cleanup_after_analysis = True
        
    print(f"‚öôÔ∏è Configuration adapt√©e: batch_size={settings.config.batch_size}")
```