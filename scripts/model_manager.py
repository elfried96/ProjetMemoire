#!/usr/bin/env python3
"""
Utilitaire de gestion des mod√®les pour Surveillance Orchestrator.
Permet d'activer/d√©sactiver KIM et de basculer entre les mod√®les facilement.
"""

import sys
import argparse
from pathlib import Path

# Ajout du r√©pertoire parent au path pour les imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.config import settings, ModelType
from src.models import get_available_models
from src.models.kim_wrapper import KIMWrapper
from src.utils.logging import get_surveillance_logger
from src.utils.memory_optimizer import MemoryOptimizer

logger = get_surveillance_logger()


def display_current_config():
    """Affiche la configuration actuelle."""
    print("üéØ CONFIGURATION ACTUELLE")
    print("=" * 50)
    
    models = get_available_models()
    
    for model_id, info in models.items():
        status = "‚úÖ ACTIV√â" if info["enabled"] else "‚ùå D√âSACTIV√â"
        available = "‚úÖ DISPONIBLE" if info["available"] else "‚ùå NON DISPONIBLE"
        primary = " (PRINCIPAL)" if info["is_primary"] else ""
        
        print(f"{info['name']}{primary}")
        print(f"  Status: {status}")
        print(f"  Disponible: {available}")
        print(f"  ID Mod√®le: {info['model_id']}")
        print()
    
    print(f"Configuration:")
    print(f"  VLM Principal: {settings.config.primary_vlm.value}")
    print(f"  Batch Size: {settings.config.batch_size}")
    print(f"  Nettoyage auto: {'Oui' if settings.config.cleanup_after_analysis else 'Non'}")


def check_gpu_status():
    """V√©rifie l'√©tat du GPU."""
    print("üñ•Ô∏è  √âTAT DU GPU")
    print("=" * 30)
    
    try:
        import torch
        
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            current_device = torch.cuda.current_device()
            gpu_name = torch.cuda.get_device_name(current_device)
            gpu_memory = torch.cuda.get_device_properties(current_device).total_memory
            gpu_memory_gb = gpu_memory / (1024**3)
            
            print(f"‚úÖ CUDA disponible")
            print(f"Nombre de GPU: {gpu_count}")
            print(f"GPU actuel: {gpu_name}")
            print(f"M√©moire GPU: {gpu_memory_gb:.1f} GB")
            
            # Test d'allocation m√©moire
            try:
                test_tensor = torch.randn(1000, 1000).cuda()
                del test_tensor
                torch.cuda.empty_cache()
                print("‚úÖ Test GPU: OK")
            except Exception as e:
                print(f"‚ö†Ô∏è  Test GPU: {e}")
        else:
            print("‚ùå CUDA non disponible")
            print("Le syst√®me utilisera le CPU (tr√®s lent pour les mod√®les)")
    
    except ImportError:
        print("‚ùå PyTorch non install√©")


def enable_kim():
    """Active KIM si possible."""
    print("üöÄ ACTIVATION DE KIM")
    print("=" * 30)
    
    if not KIMWrapper.is_available():
        print("‚ùå KIM ne peut pas √™tre activ√©:")
        
        try:
            import torch
            if not torch.cuda.is_available():
                print("  ‚Ä¢ CUDA non disponible")
            else:
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                if gpu_memory < 6:
                    print(f"  ‚Ä¢ GPU insuffisant ({gpu_memory:.1f}GB < 6GB requis)")
        except ImportError:
            print("  ‚Ä¢ PyTorch non install√©")
        
        return False
    
    settings.enable_model(ModelType.KIM, True)
    print("‚úÖ KIM activ√© avec succ√®s")
    return True


def disable_kim():
    """D√©sactive KIM."""
    print("‚èπÔ∏è  D√âSACTIVATION DE KIM")
    print("=" * 30)
    
    settings.enable_model(ModelType.KIM, False)
    
    # Bascule vers SmolVLM si KIM √©tait principal
    if settings.config.primary_vlm == ModelType.KIM:
        settings.set_primary_vlm(ModelType.SMOLVLM)
        print("üì± Basculement automatique vers SmolVLM")
    
    print("‚úÖ KIM d√©sactiv√©")


def switch_primary_model(model_name: str):
    """Bascule le mod√®le principal."""
    print(f"üîÑ BASCULEMENT VERS {model_name.upper()}")
    print("=" * 40)
    
    if model_name.lower() == "smolvlm":
        settings.set_primary_vlm(ModelType.SMOLVLM)
        print("‚úÖ SmolVLM d√©fini comme mod√®le principal")
        
    elif model_name.lower() == "kim":
        if not settings.get_model_config(ModelType.KIM).enabled:
            print("‚ùå KIM n'est pas activ√©")
            print("üí° Utilisez 'python model_manager.py --enable-kim' d'abord")
            return False
            
        if not KIMWrapper.is_available():
            print("‚ùå KIM n'est pas disponible (ressources insuffisantes)")
            return False
        
        settings.set_primary_vlm(ModelType.KIM)
        print("‚úÖ KIM d√©fini comme mod√®le principal")
        print("‚ö†Ô∏è  Attention: KIM n√©cessite plus de ressources GPU")
        
    else:
        print(f"‚ùå Mod√®le '{model_name}' non reconnu")
        return False
    
    return True


def run_diagnostics():
    """Ex√©cute un diagnostic complet du syst√®me."""
    print("ü©∫ DIAGNOSTIC DU SYST√àME")
    print("=" * 40)
    
    # V√©rification Python
    print(f"Python: {sys.version}")
    
    # V√©rification des d√©pendances critiques
    dependencies = [
        ("torch", "PyTorch pour les mod√®les ML"),
        ("transformers", "Transformers pour les mod√®les Hugging Face"),
        ("opencv-python", "OpenCV pour le traitement vid√©o"),
        ("pillow", "PIL pour le traitement d'images"),
        ("ultralytics", "YOLOv8 pour la d√©tection d'objets")
    ]
    
    print("\nüì¶ D√âPENDANCES:")
    for dep, desc in dependencies:
        try:
            __import__(dep)
            print(f"‚úÖ {dep}: OK - {desc}")
        except ImportError:
            print(f"‚ùå {dep}: MANQUANT - {desc}")
    
    # √âtat du GPU
    print()
    check_gpu_status()
    
    # Optimisations m√©moire
    print("\nüß† OPTIMISATIONS M√âMOIRE:")
    optimizer = MemoryOptimizer()
    optimizer.log_memory_status("DIAGNOSTIC")
    optimizer.auto_configure_settings()
    
    # √âtat des mod√®les
    print()
    display_current_config()
    
    # Test d'import des modules
    print("\nüß© MODULES INTERNES:")
    try:
        from src.config import settings
        print("‚úÖ Configuration: OK")
        
        from src.models import create_vlm_model, create_llm_model
        print("‚úÖ Mod√®les: OK")
        
        from src.utils.preprocessing import video_processor
        print("‚úÖ Preprocessing: OK")
        
        from src.orchestrator.controller import SurveillanceOrchestrator
        print("‚úÖ Orchestrateur: OK")
        
        from src.utils.memory_optimizer import memory_optimizer
        print("‚úÖ Optimiseur m√©moire: OK")
        
    except Exception as e:
        print(f"‚ùå Erreur import: {e}")
        
    # Recommandations
    print("\nüí° RECOMMANDATIONS:")
    info = optimizer._get_memory_info()
    if "gpu_total_gb" in info:
        gpu_gb = info["gpu_total_gb"]
        if gpu_gb < 4:
            print("  üîã GPU limit√©: Utilisez SmolVLM uniquement")
            print("  üîß batch_size=1, cleanup_after_analysis=True")
        elif gpu_gb < 8:
            print("  ‚öñÔ∏è GPU moyen: SmolVLM recommand√©, KIM possible")
            print("  üîß batch_size=2, load_in_8bit=True pour KIM")
        else:
            print("  üöÄ GPU puissant: KIM disponible avec toutes options")
            print("  üîß batch_size=4+, performances optimales")
    else:
        print("  üíª Mode CPU: SmolVLM uniquement, patience requise")
        print("  üîß batch_size=1, max_frames=5")


def setup_argument_parser():
    """Configure les arguments de ligne de commande."""
    parser = argparse.ArgumentParser(
        description="Gestionnaire de mod√®les pour Surveillance Orchestrator",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    parser.add_argument(
        "--status", "-s",
        action="store_true",
        help="Affiche l'√©tat actuel des mod√®les"
    )
    
    parser.add_argument(
        "--enable-kim",
        action="store_true",
        help="Active KIM si les ressources le permettent"
    )
    
    parser.add_argument(
        "--disable-kim",
        action="store_true",
        help="D√©sactive KIM"
    )
    
    parser.add_argument(
        "--switch-to",
        type=str,
        choices=["smolvlm", "kim"],
        help="Bascule vers le mod√®le sp√©cifi√©"
    )
    
    parser.add_argument(
        "--gpu-status",
        action="store_true",
        help="V√©rifie l'√©tat du GPU"
    )
    
    parser.add_argument(
        "--diagnostics",
        action="store_true",
        help="Ex√©cute un diagnostic complet du syst√®me"
    )
    
    parser.add_argument(
        "--memory-test",
        action="store_true",
        help="Lance les tests d'optimisation m√©moire"
    )
    
    return parser


def main():
    """Fonction principale."""
    parser = setup_argument_parser()
    args = parser.parse_args()
    
    # Si aucun argument, affiche le statut
    if not any(vars(args).values()):
        display_current_config()
        return 0
    
    if args.diagnostics:
        run_diagnostics()
        return 0
    
    if args.memory_test:
        # Import et lancement des tests m√©moire
        import subprocess
        memory_test_script = Path(__file__).parent / "memory_test.py"
        result = subprocess.run([sys.executable, str(memory_test_script)])
        return result.returncode
    
    if args.gpu_status:
        check_gpu_status()
        return 0
    
    if args.status:
        display_current_config()
        return 0
    
    if args.enable_kim:
        success = enable_kim()
        if not success:
            return 1
    
    if args.disable_kim:
        disable_kim()
    
    if args.switch_to:
        success = switch_primary_model(args.switch_to)
        if not success:
            return 1
    
    # Affiche l'√©tat final si des changements ont √©t√© faits
    if args.enable_kim or args.disable_kim or args.switch_to:
        print("\n" + "="*50)
        display_current_config()
    
    return 0


if __name__ == "__main__":
    try:
        exit(main())
    except KeyboardInterrupt:
        print("\n‚ùå Interrompu par l'utilisateur")
        exit(130)
    except Exception as e:
        logger.error(f"Erreur inattendue: {e}")
        exit(1)